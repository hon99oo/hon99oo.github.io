var store = [{
        "title": "블로그를 다시 시작해 보자",
        "excerpt":"4학년 1학기 졸업작품을 3월부터 6월까지 열심히 달렸다. 졸업작품을 끝마치고 나니 현업의 욕심이 생겨 열심히 인턴 지원을 진행하였다. 그렇게 자소서를 쓰고 대학생활을 하며 잰힝했던 포트폴리오를 정리하고 7월 11일에 ‘스페이스워크’라는 회사에 인턴 포지션으로 입사하게 되었다. 인턴 포지션에 입사한 이후로 코딩에 대한 열정이 팍 식은거 같다. 회사일은 내가 졸업작품을 했을 때 처럼 큰 열정을 쏟아 붓지 못한 채 시키는 일만 하는 수동적 인간이 되었다. 그렇게 거의 5개월을 따로 공부도 하지 않고 열정이 없는 채로 살아왔던 것 같다. 당장 내 앞에 펼쳐져 있는 숙제들도 해결하지 않고 뒤로 미뤄두고 기상 - 회사 일 쪼금 - 게임 - 취침의 쳇바퀴의 반복적 인생을 살아왔다.   인턴 포지션 종료일은 1월 11일이다. 이후 나는 졸업요건을 하나 충족하지 않아 초과학기를 해야하며 다음 취업을 준비해야 한다. 인턴 포지션 종료까지는 약 2개월 정도 남았다. 지금은 욕심이지만, 인턴 종료 이후 곧바로 다른 회사의 인턴 포지션으로 들어가거나 현재 있는 회사에 잔류 하는 것이 목표이다. 현재 다니고 있는 회사에서 열심히 하지 못했던 이유는 나에게 목표의식이 조금 사라졌다는 변명을 들 수 있을 것 같다. 다시금 목표가 생긴 현재 이를 정확히 인지하고 행동으로 실천할 때가 온 것 같다.   인턴 생활을 하기 전까지는 모두 뇌피셜로 코딩을 해오고 공부를 해왔다. 그 때는 BE와 FE의 차이점도 몰랐고 DE가 요즘 핫하다는 이야기만 듣고 무슨 일을 하는지도 모른채로 DE포지션으로 인턴을 지원했었다. 하지만, 현업 생활을 약 4개월정도 하고 난 뒤 내 주변에 현업 생활을 하고 있는 지인들의 이야기가 궁금해졌고 많은 사람들의 이야기를 듣고 싶어 일명 DevTalk을 요청하였다. 그리고 이제는 정확하지는 않지만, 개발자라는 직군이 어떻게 돌아가는지 그리고 내가 어떤 일을 할 수 있고 어떤 일을 하고 싶은지 조금은 알 수 있게 되었다.   우선 나의 문제점을 발견했다. 간단하고 명확하게 말하자면, 나는 현재 ‘코싸개’이다. 생각하지 않고 주어진 문제를 해결하기 위해 수단과 방법을 가리지 않고 그저 코드만을 작성했던 굉장히 질 나쁜 개발자였던 것이다. 생각해보면 내가 이 프로그래밍에 관해 진지하게 공부했던 적이 없다. 학문을 가르치는 대학에서 소프트웨어학과를 진학하고 전공 과목은 집중하지 않고 프로젝트를 어떻게든 이쁘게 만들기 위해서 프로젝트를 위한 공부만 했던 것 같다. 현재 사용하고 있는 기술들은 모두 근본이 되는 알고리즘과 컴퓨터구조론에서부터 비롯된 기술임을 몰랐던 것이다. 나에게 가장 부족한 점은 ‘근본 지식’을 모르는 것이다. 많이 늦었다고 말할 수 있지만, 오늘부터 ‘근본 지식’에 관련하여 몇가지를 체계적으로 공부할 생각이다.   첫번째, 알고리즘이다. 알고리즘을 제대로 배워본 적이 없다. 사실 우리학교의 전공 필수 과목이지만, 너무 어렵고 공부하기도 싫어서 대충 했던 기억이 있다. 그리고 모르는 지식이 있으면 그 때 그 때 구글링으로 일시적으로 지식의 빈자리를 매꿀 뿐이었다. 근본이 되는 알고리즘 서적으로 공부할 계획이다. 두번째, 컴퓨터구조론이다. 컴퓨터구조론 또한 우리학교의 전공 필수 과목이지만, 족보를 바탕으로 공부해서 학점은 좋게 받았지만 남아있는 지식은 없다. 알고리즘과 컴퓨터구조론을 우선 공부하여 인턴 포지션 종료 전 까지 어느정도의 지식을 확보하고 싶은 계획이다.   이후 나는 BE나 DE 직군으로 나아갈 예정이다. 현재 내가 사용하는 주 언어는 python이지만, java에도 관심이 조금씩 가고 있다. 알고리즘과 컴퓨터구조론 공부를 마치고 나면 DE의 근본책과 BE의 근본책 두가지를 구매해서 공부할 예정이다. 이 열정이 언제 식을지 모르겠지만, 현재 내 발등에는 불이 그것도 존나게 뜨거운 불이 떨어졌다.   화이팅이다 홍구야  ","categories": ["doodle"],
        "tags": ["doodle"],
        "url": "/doodle/doodle_01/",
        "teaser": null
      },{
        "title": "test post 입니다.",
        "excerpt":"You’ll find this post in your _posts directory. Go ahead and edit it and re-build the site to see your changes. You can rebuild the site in many different ways, but the most common way is to run jekyll serve, which launches a web server and auto-regenerates your site when a file is updated.   Jekyll requires blog post files to be named according to the following format:   YEAR-MONTH-DAY-title.MARKUP   Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and MARKUP is the file extension representing the format used in the file. After that, include the necessary front matter. Take a look at the source for this post to get an idea about how it works.   Jekyll also offers powerful support for code snippets:   def print_hi(name)   puts \"Hi, #{name}\" end print_hi('Tom') #=&gt; prints 'Hi, Tom' to STDOUT.  Check out the Jekyll docs for more info on how to get the most out of Jekyll. File all bugs/feature requests at Jekyll’s GitHub repo. If you have questions, you can ask them on Jekyll Talk.   ","categories": ["test post"],
        "tags": ["test","theme"],
        "url": "/test%20post/test/",
        "teaser": null
      },{
        "title": "2022년 초보 개발자의 취업 계획",
        "excerpt":"   곧 2022년이다. 2021년 한해를 마무리해보자.     2021년 : 마무리   3月-6月 졸업작품    7月-12月 인턴생활    졸업작품 하얗게 불태우고 바로 인턴 생활을 했다. 현업이 되게 궁금했는데 이 부분에 대해서는 굉장히 많은 도움이 된 것 같다. 그리고 Data Engineering 직무도 굉장히 관심 있었는데 직접 경험할 수 있어서 좋았다. 나는 조금 더 다양한 경험을 하고 싶어서  Back End 직무를 공략할 생각이다. 언어는 아무래도 java가 강력하다고 생각해서 java 공부를 시작할 것 같다.    2022년 : 11월 전까지 아래 서류들을 준비해보자      졸업요건 맞추기    토익 또는 오픽    정보처리기사    CS    Algorithm    Java 스킬    ~2022년 포트폴리오 정리    코딩 캠프(네이버부캠,우테코 등등…) 준비      Java Backend Roadmap   ","categories": ["doodle"],
        "tags": ["doodle"],
        "url": "/doodle/doodle_02/",
        "teaser": null
      },{
        "title": "Google's Neural Machine Translation System : Bridging the Gap between Human and Machine Translation 논문 리뷰",
        "excerpt":"Introduction     Neural Machine Translation            End-to-End 학습 접근 방식의 자동 번역       기존 구문 기반 번역의 약점을 극복           Neural Machine Translation 단점            데이터 양과 매개변수가 많아 훈련과 추론 속도가 느림       Rare Word 처리의 문제점       가끔씩 모든 단어에 대해 번역하지 못함           Google’s Neural Machine Translation            LSTM으로 이루어져 있는 8개의 ENCODER와 8개의 DECODER       병렬 처리 개선을 위해 DECODER의 최하층과 ENCODER의 최상층을 ATTENTION으로 연결       번역속도를 높이기 위해 low-precision arithmetic, Rare Word 처리를 위해 WordPiece 사용            Model Architecture       Model Parallelism            모델 병렬화와 데이터 병렬화 모두 사용함       Downpour SGD를 사용하여 데이터 병렬화                    여러개의 모델로 나누어, 여러개의 머신에서 동시에 학습함, 각각 학습된 gradient를 평균내어 모델에 적용           실험에서는 10개의 머신에서 128개의 문장을 Mini-batch로 사용                       모델 병렬화                    머신당 8개의 GPU 사용 ( 각 층 마다 서로 다른 GPU에 할당 )           i번째 레이어의 작업이 종료전에 i+1번째 작업 진행 가능                            Segmentation Approches     Wordpiece Model            띄어쓰기는 _, 단어는 내부단어 통계에 기반하여 띄어쓰기로 분리       띄어쓰기를 _로 치환한 이유는 차후에 문장 복원을 위해       실험에서는 wordpiece를 8K~32K에서 좋은 결과 얻음       wordpiece로도 얻을 수 없었던 rare word는 copy model을 사용                 Mixed Word/Character Model            OOV 처리를 로 하지 않고 문자 단위로 나누어 처리함       시작 문자 , 중간 문자 , 끝 문자        전체 작업 과정에서 유지한 채로 학습한 후 태그를 삭제함             Training Criteria     Maximum-liklihood 학습 방식은 로그 확률 값을 최대화하는 목적 함수 ( BLUE 평가 지표와 부합되지 않음 )        Reward개념의 목적함수 사용        r은 문장 단위 점수 ( 출력 문서와 실제 문서의 차이 계산 )   GLEU 점수 지표 사용 ( 출력 문장과 정답 문장을 1~4 토큰으로 만든 뒤 recall과 precision을 구한 뒤 더 작은 값을 GLEU로 정함 )   ML방식과 RL 방식 혼합하여 사용 이 때, a는 0.017        Quantizable Model And Quantized Inference     NMT은 연산량이 많아 Inference 시간이 오래 걸리는 것이 큰 단점   해결하기 위하여 Quantized inference 수행!        Decoder     Beam Search를 사용하여 점수 함수를 최대화 하는 시퀀스 Y를 찾음   Length normalization            길이가 더 긴 문장의 확률이 떨어지기 때문에 이를 보정하기 위하여 사용       하이퍼 파라미터 a 사용 ( 실험에서는 0.6 ~ 0.7 사용 )           Coverage Panelty            source word xi로 부터 attention weight의 합을 구함       로그를 취했기 때문에 attention weight이 편중되지 않은 source word의 값이 매우 작음 음수를 가지게 됨       실험에서는 a는 0.6 b는 0.2 사용                Experiments And Results     Data set            WMT En -&gt; Fr 36M       WMT En -&gt; De 5M           Evaluation Metrics            BLUE       implicit human evaluation ( BLUE는 번역 점수 잘 못메김 )           Training Procederue            TensorFlow 사용하여 구현       12개의 머신으로 병렬화       [-0.04, 0.04] 사이로 매개변수를 균일하게 초기화       Adam Optimizer와 SGD 혼합하여 사용 ( 첫 60k는 Adam으로 그 후로는 SGD 사용)           Learning Rate는 0.5 ( 1.2M 이후부터 200k 단위마다 반씩 줄여가며 학습 )          Conclusion     Wordpiece 모델은 번역 품질과 inference 속도를 효과적으로 높힘   모델과 데이터의 병렬화는 sequence-to-sequence NMT 모델을 일주일 안으로 효율적으로 훈련시킬 수 있음   Model quantization은 inference 속도를 가속화할 수 있어 대형 모델에 사용하기 용이함   Length-normalization, coverage penalty 등과 같은 추가 세부 사항이 NMT 시스템을 잘 작동시키게 도와줌  ","categories": ["NLP"],
        "tags": ["paper review","nlp"],
        "url": "/nlp/NLP_01/",
        "teaser": null
      },{
        "title": "Docker는 대충 이런 느낌인가?",
        "excerpt":"Docker   내가 느낀 전체적인 도커의 메커니즘 : 어떠어떠한 것을 빌드해서 이미지를 만들고  -&gt; 이미지를 도커로 띄운 뒤 -&gt; 이미지를 받아서 로컬에서 개발작업을 진행   !!많은 시행착오를 거쳐 도커의 메커니즘에 대해 이해가 조금 되었다.     Dockerfile을 만든다.   해당 디렉토리 위치에서 docker build를 한다.   docker build을 하면 이미지가 생성된다.   이미지가 생성됐으면, 해당 이미지로 docker run을 한다.   docker run을 하면 컨테이너가 만들어지고 해당 이미지를 컨테이너 안으로 넣는다?띄운다?   그럼 환경셋팅이 된다…?   틀린 부분도 있겠지만 아주 조오금 조오오오오금 메커니즘이 이해가 됐다.   앗 참고로 음… 저런 run이니 이미지 파일들이니 어떤 컨테이너가 실행중인지를 GUI로 확인할 수 있는 프로그램이 Docker Desktop 같다 ㅎㅎ..   추가적으로 환경세팅을 완료한 것 같다. 음… 위의 6번까지 진행한 후에          컨테이너를 만들면 어떠한 가상환경이 만들어지는 것 같다.            그럼 그 컨테이너에가 파이썬 환경으로 이루어져있고 추가로 다양한 패키지들이 들어있다.            그럼 그 환경을 내가 사용하고 있는 Pycharm과 연동을 하는 거다.       어떻게 하냐면 파이참 프로젝트의 인터프리터를 해당 컨테이너에 있는 파이썬path로 설정해주는거다. *https://i-am-eden.tistory.com/13        그리고 코딩하면 된다 ㅎㅎ ***            도커엔진 - 도커를 실행하면 Dockered라는 데몬 프로그램이 서버로 실행.   **여기서 잠깐! 데몬 프로그램이 뭘까?   https://blogger.pe.kr/770  (포그라운드, 백그라운드, 데몬 프로세스)    https://haruhiism.tistory.com/9            도커실행 : 도커 이미지를 받아서 컨테이너로 실행   ** -it 라는 명령어는 -i와 -t 옵션이 합쳐진 옵션, -i는 호스트와 컨테이너 상호 입출력을 맞추고, -t는 TTY를 활성화해서 컨테이너에 터미널로 입력이 가능하게 한다.   ** TTY가 뭐지?!   https://cosmosproject2015.tistory.com/143 (TTY, PTS, PTY)            도커 volume : 데이터를 컨테이너에 저장하지 않고 호스트에 저장하는 방식   https://www.daleseo.com/docker-volumes-bind-mounts/       도커빌드 : Dockerfile로 사용자 정의 이미지를 만듬   *공부하기 : 도커 아키텍쳐, 컨테이너-OS 간의 통신 구조   ** Docker의 개념 및 핵심 설명 :  https://khj93.tistory.com/entry/Docker-Docker-%EA%B0%9C%EB%85%90    Docker 예제 실습중 갱장히 이상한 오류가 발생했다.   failed to solve with frontend dockerfile.v0: failed to read dockerfile: open /var/lib/docker/tmp/buildkit-mount174403522/Dockerfile: no such file or directory   구글링을 계속 해봤지만 dockerfile -&gt; Dockerfile 로 이름을 바꾸라는 답변밖에 없었다.   하지만, 오류가 고쳐지지 않았고 터미널을 Open한 디렉토리 경로를 상위 폴더 위치로 open을 해서 났던 오류였다 ㅎㅎ  ","categories": ["Docker"],
        "tags": ["Docker"],
        "url": "/docker/docker_01/",
        "teaser": null
      },{
        "title": "TDD와 each map",
        "excerpt":"TDD   TDD(Test Driven Development)란 본격적인 개발에 들어가기 전에 테스트 계획 및 코드를 작성하는 것을 의미한다. 테스트가 개발을 이끌어 나가는 것이다. 예를들어, 개발 중 에러가 발생했을 때 소규모 개발에서는 큰 문제가 되지는 않지만, 대규모의 개발 상황에서는 수 많은 모듈과 함수간 종속성들이 굉장히 많은 시간을 괴롭히게 된다. 이러한 문제점을 해결하기 위해서 테스트 주도 개발이 등장했다.   나는 pytest를 사용할 것이다. https://binux.tistory.com/47   일단, monkeypatch.setattr 살펴보자.  이것은 어떤것을 하냐면, mocking이다. Mocking은 실제 값이 아닌 가짜 값을 만들어내는 것이다.   음 예를들면 Upload 클래스가 있다.   Class Upload    |_ Def Extract   |_ Def Transform   |_ Def Load   이렇게 되어있을 때 나는 Transform 부분만 테스트하고 싶다. 하지만 함수의 종속성으로 인하여 Transform에서 사용되는 data는 Extract로 부터 참조되며 Extract에서 추출되는 data는  특정 라이브러리의 기능을 참조한다. 나는 Transform 부분만 테스트하고 싶지만 이런 경우에 Extract부터 특정 라이브러리으 기능까지 테스트해야되는 상황에 처한 것이다. 이런 경우에 이제 Mocking이라는 기술을 쓴다. pytest에서도 제공하는 function이 있지만, 단순한 예를 하나 들자면 정답과 인풋값을 csv파일이나 등등으로 미리 만들어서 로컬에서 참조하도록 코드를 작성하면 된다.   하지만 이때, 테스트 코드에서 원코드를 실행할 때 원코드의 Extract가 실행 되기 때문에 monkeypatch.setattr 같은 기능으로 해당 function을 사용하지 않고 넘겨주는 기능을 넣어줘야한다.    each map  each map을 알아야한다.  음 지금 내가 하는 것은 DB -&gt; transform -&gt; DB 적재이다. transform에서 전처리 및 parsing을 해주는데, transform에서 이뤄지는 작업은 모든 Dataframe이 메모리 상으로 올라가게 된다. 작은 task면 문제없이 실행 되겠지만, 큰 규모의 task는 메모리를 많이 차지하게 되어 에러가 날 수 있다. 이럴 때 사용 하는 것이 each map이다. each map은 dataframe에서 row 별로 메모리 상으로 올린다. 이후 해당 row에서 특정 처리를 진행 후에 buffer로 옮긴 뒤 DB로 적재를 한다. 이 때 조심해야 하는 부분은 seperate다. row에서 컬럼으로 구분하는 seperate값을 잘 이용해야지 에러가 나지 않을 것이다.    즉! pytest 부분을 더 공부하고 적절한 testset을 생각해보고, testcode를 작성해보자!  ","categories": ["Docker"],
        "tags": ["Docker"],
        "url": "/docker/doodle_03/",
        "teaser": null
      },{
        "title": "CS:APP - 01",
        "excerpt":"CS:APP  Computer Systems A Programmer’s Perspective, CSAPP로도 잘 알려져있는 컴퓨터 구조론의 바이블이다. 이 책을 통해서 컴퓨터구조론을 다시 공부해볼 생각이다. 군대 전역 직후 2학년 2학기로 복학해서 컴퓨터 구조론 전공 수업을 들었지만 학점을 위한 공부만 해서 남아있는게 없는 것 같다. 인턴 생활을 하면서 다양한 부분에서 어려움을 겪었는데 기초를 몰라서 헤메고 있다는 느낌을 굉장히 많이 받았다.   첫 페이지를 읽었을 때 이 책으로 정하길 정말 잘했다는 생각이 들었다. 전공 수업때 사용했던 컴퓨터구조론 책은 제작자의 관점에서 기술 되었다는 느낌을 강하게 받았었다. 하지만, CSAPP는 프로그래머의 관점에서 기술하였고, 컴퓨터구조론의 시스템들을 어떻게 사용해서 좋은 프로그램을 개발할 수 있는지를 배울 수 있다고 한다.  인턴 생활을 하면서 실제 현업을 겪고 느꼇던 강한 의문들을 해결할 수 있을 것 같은 느낌이다.   책의 목차는 정보의 표현과 처리로 시작하여 프로그램의 기계어 표현, 프로세서 구조, 프로그램 성능 최적화, 메모리 계층구조, 링커, 예외적인 제어흐름, 가상메모리, 시스템 수준 입출력, 네트워크 프로그래밍, 동시성 프로그래밍  순서로 이어져 있다. 많은 사람들은 6장 메모리 계층구조, 7장 링커의 전까지 읽어도 좋다고 하지만, 가능하다면 12장 동시성 프로그래밍까지 읽어볼 생각이다.   Chapter 01. 컴퓨터 시스템으로의 여행     시스템 구현방식은 변하지만 근본적인 개념들은 변하지 않는다.   프로그래머들로 하여금 컴포넌트들이 어떻게 동작하고 프로그램 성능과 정확성에 어떤 영향을 주는지 알 수 있다.   1.1 정보는 비트와 컨텍스트로 이루어진다.     텍스트 문자 -&gt; 아스키(ASCII) 표준 사용하여 표현 -&gt; 각 문자를 바이트 길이의 정수 값으로 표현 -&gt; 연속된 바이트 파일 저장   1.2 프로그램은 다른 프로그램에 의해 다른 형태로 번역된다.     hello.c 실행 -&gt; 저급 기계어 인스트럭션들로 번역 -&gt; (실행가능 목적 프로그램)으로 합쳐져 바이너리 디스크 파일로 저장  -&gt; 컴파일러 드라이브는 유닉스 시스템에서 소스파일에서 오브젝트 파일로 변경 -&gt; 4개의 단계를 거쳐서 실행            4개의 단계:                    전처리기           컴파일러           어셈블러           링커                           1.3 컴파일 시스템이 어떻게 동작하는지 이해하는 것은 중요하다.     프로그램 성능 최적화하기            eg1) switch문은 if-else문을 연속해서 사용하는 것보다 효율적인가?       eg2) while 루프는 for 루프보다 더 효율적일까?       eg3) 포인터 참조가 배열 인덱스보다 더 효율적인가?           링크 에러 이해하기            eg1) 정적변수와 전역변수의 차이는 무엇인가?       eg2) 다른 파일에 동일한 이름의 두 개의 전역변수를 정의한다면 무슨 일이 일어나는가?           보안 약점 피하기            eg1) 프로그램 스택에 데이터와 제어 정보가 저장되는 방식은 무엇인가?           1.4 프로세서는 메모리에 저장된 인스트럭션을 읽고 해석한다.     인스트럭션이란 : 컴퓨터에게 일을 시키는 단위(기계어)       시스템의 하드웨어 조직            버스 : 시스템 내를 관통하는 전기적 배선군       입출력 장치 : 시스템과 외부세계외의 연결 담당       메인 메모리 : 프로세서가 프로그램을 실행하는 동안 데이터와 프로그램을 모두 저장하는 임시 저장장치       프로세서 : 인스트럭션들을 해독(실행)하는 엔진                    인스트럭션의 요청에 의해 CPU(프로세서)가 실행하는 단순한 작업의 예                            적재(load), 저장(store), 작업(operate), 점프(jump)                                                   프로그램의 실행 (그림 추가 예정 ㅎㅎ..)   1.5 캐시가 중요하다.     hello 프로그램의 기계어 인스트럭션들은 본래 하드디스크에 저장되어 있다.   프로그램이 로딩될 때 이들은 메인 메모리로 복사된다.   이 작업이 시간이 너무 오래 걸려서 “단기간에 필요로 할 가능성이 높은 정보를 임시로 저장하는” 캐시 메모리가 설계 되었다.   캐시 시스템의 이면에 깔려 있는 아이디어는 프로그램이 지엽적인 영역의 코드와 데이터를 액세스하는 경향인 지역성을 활용하였다.   1.6 저장장치들은 계층구조를 이룬다.     모든 컴퓨터 시스템의 저장장치즈들은 메모리 계층구조로 구성되어 있다.   (그림 추가 예정 ㅎㅎ..)   1.7 운영체제는 하드웨어를 관리한다.     운영체제는 두 가지 주요 목적을 가지고 있다.            제멋대로 동작하는 응용프로그램들이 하드웨어를 잘못 사용하는 것을 막기 위해       응용프로그램들이 단순하고 균일한 메커니즘을 사용하여 복잡하고 매우 다른 저수준 하드웨어 장치들을 조작할 수 있도록 하기 위해           위 두가지 목표를 위해 근본적인 추상화를 통해 달성하고 있다.   추상화 결과            프로세스 : 프로세서, 메인 메모리, 입출력장치 모두의 추상화 결과       가상 메모리 : 메인 메모리와 디스크 입출력 장치의 추상화       파일 : 입출력장치의 추상화           1.8 시스템은 네트워크를 사용하여 다른 시스템과 통신한다.     네트워크는 또 다른 입력장치로 볼 수 있다.   시스템이 메인 메모리로부터 네트워크 어댑터로 일련의 바이트를 복사할 때, 데이터는 로컬디스크 드라이브 대신에 네트워크를 통해서 다른 컴퓨터로 이동된다.   1.9 중요한 주제들     Amdahl의 법칙            우리가 어떤 시스템의 한 부분의 성능을 개선할 때, 전체 시스템 성능에 대한 효과는 구 부분이 얼마나 중요한가와 이 부분이 얼마나 빨라졌는가에 관계된다.           동시성과 병렬성            동시성 : 다수의 동시에 벌어지는 일을 갖는 시스템에 관한 일반적인 개념       병렬성 : 동시성을 사용해서 시스템을 보다 더 빠르게 동작하도록 하는 것       쓰레드 수준 동시성                    쓰레드를 이용하면 한 개의 프로세스 내에서 실행되는 다수의 제어흐름을 가질 수 있음                       인스트럭션 수준 병렬성                    프로세서들은 훨씬 낮은 수준에서의 추상화로 여러 개의 인스트럭션을 한 번에 실행할 수 있음                           컴퓨터 시스템에서 추상화의 중요성            추상화의 사용은 전산학에서 가장 중요한 개념!           1.10 요약     컴퓨터 내의 정보는 비트들의 그룹으로 표시   컴파일러와 링커에 의해 바이너리 실행파일들로 번역   프로세서는 메인 메모리에 저장된 바이너리 인스트럭션을 읽고 해석   컴퓨터는 대부분의 시간을 메모리, 입출력장치, CPU 레지스터 간에 데이터를 복사하고 쓰는 데 사용   위와 같은 이유로 시스템의 저장장치들은 계층구조 형성   운영체제 커널은 응용프로그램과 하드웨어 사이에서 중간자 역할 수행   네트워크는 컴퓨터 시스템이 서로 통신할 수 있는 방법 제공   ","categories": ["CS:APP"],
        "tags": ["CS:APP","CS"],
        "url": "/cs:app/csapp_01/",
        "teaser": null
      }]

I"‰<h1 id="introduction">Introduction</h1>
<ul>
  <li>Multi-Task Learning(MTL)ì€ ìƒˆë¡œìš´ Taskë¥¼ í•™ìŠµí•˜ëŠ” ë° ë„ì›€ì´ ë˜ë„ë¡ ì´ì „ ì‘ì—…ì—ì„œ í•™ìŠµëœ ì§€ì‹ì„ ì ìš©í•˜ëŠ” ì¸ê°„ í•™ìŠµ í™œë™ì—ì„œ ì˜ê°ì„ ë°›ìŒ</li>
  <li>Deep neural networks(DNN)ë¥¼ ì´ìš©í•œ representation learningì— MTLì„ ì ìš©í•˜ëŠ” ê²ƒì— ëŒ€í•œ ê´€ì‹¬ì´ ë†’ì•„ì§€ê³  ìˆìŒ
    <ul>
      <li>DNNì„ ì´ìš©í•œ representation learningì€ ë§ì€ ì–‘ì˜ ë°ì´í„°ë¥¼ ìš”êµ¬í•¨, MTLì€ ë§ì€ taskì—ì„œì˜ supervised labeled dataë¥¼ ì œê³µí•¨</li>
      <li>MTLì€ íŠ¹ì • Taskì— Overfitting ë˜ì§€ ì•Šë„ë¡ Regularization íš¨ê³¼ë¥¼ ì¤Œ</li>
    </ul>
  </li>
  <li>MTLê³¼ ëŒ€ì¡°ì ìœ¼ë¡œ, Language Modelì€ ëŒ€ìš©ëŸ‰ì˜ unsupervised datasetì„ í™œìš©í•˜ì—¬ ëª¨ë¸ì„ í•™ìŠµí•¨
    <ul>
      <li>ELMo, GPT, BERT</li>
    </ul>
  </li>
  <li>MT-DNNì€ Language Model Pre-Trainingì„ í™œìš©í•œ BERTì— Multi-task learningì„ ì ìš©í•˜ì—¬ ì„±ëŠ¥ì„ ê°œì„ í•œ ëª¨ë¸
<br /><br /></li>
</ul>

<h1 id="tasks">Tasks</h1>
<ul>
  <li>GLUEì˜ 9ê°œ taskë¥¼ MTLì— í™œìš©</li>
  <li>Single Sentence Classification
    <ul>
      <li>í•˜ë‚˜ì˜ ë¬¸ì¥ì´ ì£¼ì–´ì¡Œì„ ë•Œ ë¬¸ì¥ì˜ Classë¥¼ ë¶„ë¥˜í•˜ëŠ” Task</li>
      <li>CoLA : ë¬¸ì¥ì´ ë¬¸ë²•ì ìœ¼ë¡œ ë§ëŠ”ì§€ ë¶„ë¥˜ (True/False)</li>
      <li>SST-2 : ì˜í™” Review ë¬¸ì¥ì˜ ê°ì • ë¶„ë¥˜ (Poistive/Negative)</li>
    </ul>
  </li>
  <li>Text Similarity
    <ul>
      <li>ë¬¸ì¥ ìŒì´ ì£¼ì–´ì¡Œì„ ë•Œ, ì ìˆ˜ë¥¼ ì˜ˆì¸¡í•˜ëŠ” Regression Task</li>
      <li>STB-B : ë¬¸ì¥ ê°„ì˜ ì˜ë¯¸ì  ìœ ì‚¬ë„ë¥¼ ì ìˆ˜ë¡œ ì˜ˆì¸¡</li>
    </ul>
  </li>
  <li>Pairwise Text Classification
    <ul>
      <li>ë¬¸ì¥ ìŒì´ ì£¼ì–´ì¡Œì„ ë•Œ, ë¬¸ì¥ì˜ ê´€ê³„ë¥¼ ë¶„ë¥˜í•˜ëŠ” Task</li>
      <li>RTE, MNLI : ë¬¸ì¥ ê°„ì˜ ì˜ë¯¸ì  ê´€ê³„ë¥¼ 3ê°€ì§€ë¡œ ë¶„ë¥˜ (Entailment, Contradiction, Neutral)
â€“ QQP, MRPC : ë¬¸ì¥ ê°„ ì˜ë¯¸ê°€ ê°™ìŒ ì—¬ë¶€ë¥¼ ë¶„ë¥˜ (True/False)
â€“ Relevance Ranking
â€“ QNLI : ì§ˆë¬¸ê³¼ í•´ë‹¹ ì§€ë¬¸ ì¤‘ í•œ ë¬¸ì¥ì´ ìŒìœ¼ë¡œ ì£¼ì–´ì¡Œì„ ë•Œ í•´ë‹¹ ì§€ë¬¸ ë¬¸ì¥ì— ì§ˆë¬¸ì˜ ë‹µì´ ìˆëŠ”ì§€ ì—¬ë¶€ë¥¼ ë¶„ë¥˜ (True/False)
â€“ MT-DNNì—ì„œëŠ” ì´ë¥¼ Rank ë°©ì‹ìœ¼ë¡œ ë°”ê¾¸ì–´ ëª¨ë“  ì§€ë¬¸ ë¬¸ì¥ì— ì •ë‹µì´ ìˆì„ ê°€ëŠ¥ì„±ì„ Scoring í•˜ì—¬ ê°€ì¥ Scoreê°€ ë†’ì€ ì§€ë¬¸ ë¬¸ì¥ì„ Trueë¡œ ë¶„ë¥˜í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ Task ìˆ˜í–‰
<br /><br /></li>
    </ul>
  </li>
</ul>

<h1 id="model-architecture">Model Architecture</h1>

<p><img src="../../assets/img/nlp/04/img.png" width="80%" height="100%" />
â€“ Lexicon Encoder
  â€“ Token Embedding
    â€“ ë§¨ ì•ì— [CLS] í† í°ì„ ì¶”ê°€. ì¶”í›„ Outputì—ì„œ Classification ë“±ì„ ìœ„í•´ ì‚¬ìš©ë¨
    â€“ ë§Œì•½ ë¬¸ì¥ìŒì´ ë“¤ì–´ì˜¨ë‹¤ë©´ ê° ë¬¸ì¥ì€ Wordpieceë¡œ Toenization ë˜ë©° [SEP] Tokenì´ ë‘ ë¬¸ì¥ ì‚¬ì´ì˜ êµ¬ë¶„ìë¡œ ì‚¬ìš©ë¨
  â€“ Sentence Embedding - 1ë²ˆì§¸ í˜¹ì€ 2ë²ˆì§¸ ë¬¸ì¥ì„ì„ í‘œí˜„í•˜ëŠ” Vector
  â€“ Positional Embedding - ê° Tokenì˜ ìœ„ì¹˜ ì •ë³´ë¥¼ í‘œí˜„í•˜ëŠ” Vector</p>

<p><img src="../../assets/img/nlp/04/img_1.png" width="80%" height="100%" /></p>
<ul>
  <li>Transformer Encoder
â€“ Lexicon Encoderë¡œ ë¶€í„° ê° Tokenì˜ Input Vectorë¥¼ ì…ë ¥ìœ¼ë¡œ ë°›ì•„ Ouput Vector ì¶”ì¶œ
â€“ BERT ëª¨ë¸ê³¼ ë‹¬ë¦¬ taskë³„ë¡œ fine-tunningí•˜ì§€ ì•Šê³  MTLë¡œ fine-tunning í•¨</li>
</ul>

<p><img src="../../assets/img/nlp/04/img_2.png" width="80%" height="100%" /></p>
<ul>
  <li>Single-Sentence Classification Ouput
â€“ [CLS] Tokenê³¼ Task Specific Parameterì˜ ê³±ì— Softmaxë¥¼ ì·¨í•˜ì—¬ Ouput ì¶”ì¶œ</li>
</ul>

<p><img src="../../assets/img/nlp/04/img_3.png" width="60%" height="100%" /></p>
<ul>
  <li>Text Similarity Ouput
â€“ [CLS] Tokenì„ í™œìš©í•˜ì—¬ Task Specific Parameterì™€ ê³±í•œ í›„ sigmoid functionì„ ì‚¬ìš©í•˜ì—¬ Scoreë¥¼ ì˜ˆì¸¡</li>
</ul>

<p><img src="../../assets/img/nlp/04/img_4.png" width="60%" height="100%" /></p>

<ul>
  <li>Pairwise Text Classification Ouput
â€“ BERTì™€ ë‹¤ë¥´ê²Œ Stochastic Answer Network(SAN)ë¥¼ ì´ìš©í•¨
  â€“ NLIì˜ ê¸°ì¡´ SOTA ëª¨ë“ˆ, ì£¼ì–´ì§„ ë¬¸ì¥ë“¤ì— ëŒ€í•œ Multi-step Reasoningì„ ëª¨ë¸ë§í•˜ëŠ” êµ¬ì¡° (í•œë²ˆì— classification ê²°ê³¼ë¥¼ ì˜ˆì¸¡í•˜ì§€ ì•Šê³  ì—¬ëŸ¬ë²ˆì˜ ì˜ˆì¸¡ì„ í†µí•œ Reasoningìœ¼ë¡œ ê²°ê³¼ë¥¼ ì˜ˆì¸¡)
  â€“ SANì€ GRUëª¨ë“ˆì— ì£¼ì–´ì§„ ë¬¸ì¥ìŒì˜ representationì„ Input ë° hidden stateë¡œ ë„£ëŠ” ê³¼ì •ì„ kë²ˆ ë°˜ë³µí•¨ìœ¼ë¡œì¨ ì •ì œëœ representationì„ ì–»ê³  ì´ë¥¼ ì´ìš©í•˜ì—¬ ìµœì¢… ì˜ˆì¸¡</li>
</ul>

<p><img src="../../assets/img/nlp/04/img_5.png" width="100%" height="100%" /></p>

<p><img src="../../assets/img/nlp/04/img_6.png" width="100%" height="100%" /></p>

<ul>
  <li>ê° stepì„ ì§„í–‰í• ë•Œë§ˆë‹¤ linear classifierë¥¼ ê±°ì³ ê° í´ë˜ìŠ¤ì— ëŒ€í•œ í™•ë¥  ë¶„í¬ ê³„ì‚°</li>
</ul>

<p><img src="../../assets/img/nlp/04/img_7.png" width="100%" height="100%" /></p>

<ul>
  <li></li>
</ul>
:ET